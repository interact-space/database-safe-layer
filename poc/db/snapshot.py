"""
Database Snapshot Management
æ”¯æŒåˆ›å»ºæ•°æ®åº“å¿«ç…§å’Œå›æ»šåŠŸèƒ½
"""
import os
import json
import datetime
from typing import Optional, Dict, Any
from sqlalchemy import text, inspect
from poc.db.database import DatabaseManager
from poc.db.config import settings
from dotenv import load_dotenv

load_dotenv()

SNAPSHOTS_DIR = os.path.join(os.getcwd(), "poc", "snapshots")  if os.getcwd().endswith("poc") else os.path.join(os.getcwd(), "snapshots")
os.makedirs(SNAPSHOTS_DIR, exist_ok=True)

def create_snapshot(snapshot_id: Optional[str] = None) -> Dict[str, Any]:
    """
    åˆ›å»ºæ•°æ®åº“å¿«ç…§
    å¯¹äº PostgreSQL/Supabaseï¼Œæˆ‘ä»¬ä¿å­˜è¡¨ç»“æ„å’Œæ•°æ®
    å¯¹äº SQLiteï¼Œæˆ‘ä»¬ç›´æ¥å¤åˆ¶æ•°æ®åº“æ–‡ä»¶
    
    Returns:
        Dict with snapshot_id and metadata
    """
    if snapshot_id is None:
        ts = datetime.datetime.utcnow().strftime("%Y%m%d_%H%M%S")
        snapshot_id = f"SNAPSHOT_{ts}"
    
    db = DatabaseManager(settings.DB_URL, echo=False)
    snapshot_meta = {
        "snapshot_id": snapshot_id,
        "timestamp": datetime.datetime.utcnow().isoformat(),
        "db_url": settings.DB_URL,
        "tables": {}
    }
    
    try:
        with db.session() as s:
            # è·å–æ‰€æœ‰è¡¨å
            inspector = inspect(db.engine)
            tables = inspector.get_table_names()
            
            # å¯¹äºæ¯ä¸ªè¡¨ï¼Œä¿å­˜è¡¨ç»“æ„å’Œæ•°æ®
            for table_name in tables:
                # è·å–è¡¨ç»“æ„
                columns = inspector.get_columns(table_name)
                table_structure = {col['name']: str(col['type']) for col in columns}
                
                # è·å–æ•°æ®
                result = s.execute(text(f"SELECT * FROM {table_name}"))
                rows = result.fetchall()
                data = [dict(row._mapping) for row in rows]
                
                snapshot_meta["tables"][table_name] = {
                    "structure": table_structure,
                    "row_count": len(data),
                    # æ³¨æ„ï¼šå¯¹äºå¤§è¡¨ï¼Œå¯èƒ½åªä¿å­˜å‰1000è¡Œä½œä¸ºç¤ºä¾‹
                    "data_sample": data[:1000] if len(data) > 1000 else data,
                    "has_more": len(data) > 1000
                }
        
        # ä¿å­˜å¿«ç…§å…ƒæ•°æ®åˆ°æ–‡ä»¶
        snapshot_path = os.path.join(SNAPSHOTS_DIR, f"{snapshot_id}.json")
        with open(snapshot_path, "w", encoding="utf-8") as f:
            json.dump(snapshot_meta, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"âœ… Snapshot created: {snapshot_id}")
        return snapshot_meta
        
    except Exception as e:
        raise RuntimeError(f"Failed to create snapshot: {str(e)}")


def load_snapshot(snapshot_id: str) -> Dict[str, Any]:
    """åŠ è½½å¿«ç…§å…ƒæ•°æ®"""
    snapshot_path = os.path.join(SNAPSHOTS_DIR, f"{snapshot_id}.json")
    if not os.path.exists(snapshot_path):
        raise FileNotFoundError(f"Snapshot not found: {snapshot_id}")
    
    with open(snapshot_path, "r", encoding="utf-8") as f:
        return json.load(f)

def rollback_to_snapshot(snapshot_id: str, confirm: bool = False) -> Dict[str, Any]:
    """
    å›æ»šåˆ°æŒ‡å®šçš„å¿«ç…§ (PostgreSQL ä¸“ç”¨ç‰ˆ)
    ç­–ç•¥ï¼š
    1. æ¸…ç†ï¼šåˆ é™¤å½“å‰å­˜åœ¨ä½†å¿«ç…§ä¸­ä¸å­˜åœ¨çš„è¡¨ã€‚
    2. æ¢å¤ï¼šå¯¹å¿«ç…§ä¸­çš„æ¯å¼ è¡¨ï¼ŒDROP åŸè¡¨ (CASCADE)ï¼Œç„¶åä»å¤‡ä»½è¡¨é‡å»ºã€‚
    
    Args:
        snapshot_id: å¿«ç…§ID
        confirm: æ˜¯å¦ç¡®è®¤æ‰§è¡Œå›æ»š
    
    Returns:
        å›æ»šç»“æœä¿¡æ¯
    """
    if not confirm:
        raise ValueError("Rollback requires explicit confirmation")
    
    # å‡è®¾ load_snapshot è¿”å›çš„ç»“æ„å¦‚ä¸‹ï¼š
    # {
    #   "tables": {
    #      "person": { 
    #          "backup_table_name": "backup_person_17012345", 
    #          "ddl": "CREATE TABLE person (...)" (å¯é€‰)
    #      }
    #   }
    # }
    snapshot = load_snapshot(snapshot_id)
    url= settings.DB_URL
    db = DatabaseManager(settings.DB_URL, echo=False)
    current_dialect = db.engine.dialect.name
    print(f"\n[DEBUG] å½“å‰æ•°æ®åº“ç±»å‹: {current_dialect}")
    print(f"[DEBUG] è¿æ¥å­—ç¬¦ä¸² (DB_URL): {settings.DB_URL}")
    
    try:
        with db.session() as s:
            # 1. è·å–å½“å‰æ•°æ®åº“çŠ¶æ€
            inspector = inspect(db.engine)
            # æ³¨æ„: è¿™é‡Œæœ€å¥½æŒ‡å®š schemaï¼Œé»˜è®¤ public
            current_tables = set(inspector.get_table_names(schema="public"))
            snapshot_tables = set(snapshot["tables"].keys())
            
            # 2.ã€æ¸…ç†é˜¶æ®µã€‘åˆ é™¤å¿«ç…§ä¸­ä¸å­˜åœ¨çš„"æ–°å¢è¡¨"
            # ä¾‹å¦‚ï¼šå¿«ç…§åç”¨æˆ·æ–°å»ºäº†ä¸€ä¸ª table_xï¼Œå›æ»šæ—¶éœ€è¦åˆ æ‰å®ƒ
            tables_to_drop = current_tables - snapshot_tables
            for table in tables_to_drop:
                print(f"Dropping new table: {table}")
                # PostgreSQL å…³é”®ï¼šä½¿ç”¨ CASCADE çº§è”åˆ é™¤ä¾èµ–é¡¹ï¼ˆå¦‚å¤–é”®ã€è§†å›¾ï¼‰
                s.execute(text(f"DROP TABLE IF EXISTS {table} CASCADE"))
            
            # 3.ã€æ¢å¤é˜¶æ®µã€‘é€è¡¨æ¢å¤
            for original_table, table_info in snapshot["tables"].items():
                backup_table = table_info.get("backup_table_name")
                
                if not backup_table:
                    print(f"Warning: No backup table found for {original_table}, skipping.")
                    continue

                print(f"Restoring {original_table} from {backup_table}...")

                # A. åˆ é™¤ç°æœ‰çš„è„è¡¨ (CASCADE ç¡®ä¿å³ä½¿æœ‰å¤–é”®ä¹Ÿèƒ½åˆ æ‰)
                s.execute(text(f"DROP TABLE IF EXISTS {original_table} CASCADE"))
                
                # B. é‡å»ºè¡¨å¹¶æ¢å¤æ•°æ®
                # æ–¹æ¡ˆ 1 (æ¨è): å¦‚æœä½ ä¿å­˜äº†åŸå§‹ DDL (CREATE TABLE è¯­å¥)
                # ä¼˜ç‚¹ï¼šèƒ½å®Œç¾æ¢å¤ç´¢å¼•ã€é»˜è®¤å€¼ã€çº¦æŸã€ä¸»é”®
                if "ddl" in table_info and table_info["ddl"]:
                    # 1. æ‰§è¡ŒåŸå§‹å»ºè¡¨è¯­å¥
                    s.execute(text(table_info["ddl"]))
                    # 2. æ’å…¥æ•°æ®
                    s.execute(text(f"INSERT INTO {original_table} SELECT * FROM {backup_table}"))
                
                # æ–¹æ¡ˆ 2 (å…œåº•): å¦‚æœæ²¡æœ‰ DDLï¼Œç›´æ¥ç”¨ CREATE AS SELECT
                # ç¼ºç‚¹ï¼šä¼šä¸¢å¤±ä¸»é”®(PK)ã€ç´¢å¼•(Indexes)å’Œé»˜è®¤å€¼(Defaults)ï¼Œåªä¿ç•™æ•°æ®å’Œåˆ—ç±»å‹
                else:
                    s.execute(text(f"CREATE TABLE {original_table} AS SELECT * FROM {backup_table}"))
            
            s.commit()
        
        return {
            "status": "success",
            "snapshot_id": snapshot_id,
            "message": f"Successfully rolled back to snapshot {snapshot_id}"
        }
        
    except Exception as e:
        # å‘ç”Ÿé”™è¯¯å›æ»šäº‹åŠ¡
        # æ³¨æ„ï¼šåœ¨æŸäº›æ•°æ®åº“é©±åŠ¨ä¸­ï¼ŒDDL (DROP/CREATE) å¯èƒ½ä¼šè‡ªåŠ¨æäº¤ï¼Œä½†åœ¨ Postgres äº‹åŠ¡å—ä¸­é€šå¸¸æ˜¯å¯ä»¥å›æ»šçš„
        raise RuntimeError(f"Failed to rollback: {str(e)}")

# def rollback_to_snapshot(snapshot_id: str, confirm: bool = False) -> Dict[str, Any]:
#     """
#     å›æ»šåˆ°æŒ‡å®šçš„å¿«ç…§
#     æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªå±é™©æ“ä½œï¼Œéœ€è¦ç¡®è®¤
    
#     Args:
#         snapshot_id: å¿«ç…§ID
#         confirm: æ˜¯å¦ç¡®è®¤æ‰§è¡Œå›æ»š
    
#     Returns:
#         å›æ»šç»“æœä¿¡æ¯
#     """
#     if not confirm:
#         raise ValueError("Rollback requires explicit confirmation")
    
#     snapshot = load_snapshot(snapshot_id)
#     db = DatabaseManager(settings.DB_URL, echo=False)
    
#     try:
#         with db.session() as s:
#             # è·å–å½“å‰æ‰€æœ‰è¡¨
#             inspector = inspect(db.engine)
#             current_tables = set(inspector.get_table_names())
#             snapshot_tables = set(snapshot["tables"].keys())
            
#             # åˆ é™¤å¿«ç…§ä¸­ä¸å­˜åœ¨çš„è¡¨
#             tables_to_drop = current_tables - snapshot_tables
#             for table in tables_to_drop:
#                 s.execute(text(f"DROP TABLE IF EXISTS {table} CASCADE"))
            
#             # æ¢å¤æ¯ä¸ªè¡¨
#             for table_name, table_info in snapshot["tables"].items():
#                 # åˆ é™¤ç°æœ‰è¡¨
#                 s.execute(text(f"DROP TABLE IF EXISTS {table_name} CASCADE"))
                
#                 # é‡æ–°åˆ›å»ºè¡¨ç»“æ„ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…åº”è¯¥ä½¿ç”¨DDLï¼‰
#                 # æ³¨æ„ï¼šè¿™é‡Œåªæ˜¯æ¼”ç¤ºï¼Œå®é™…åº”è¯¥ä¿å­˜å®Œæ•´çš„DDLè¯­å¥
#                 structure = table_info["structure"]
                
#                 # æ¢å¤æ•°æ®
#                 if table_info.get("data_sample"):
#                     # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æ ¹æ®è¡¨ç»“æ„é‡å»ºè¡¨
#                     # ç”±äºæˆ‘ä»¬ä¿å­˜çš„æ˜¯æ•°æ®æ ·æœ¬ï¼Œå®Œæ•´çš„å›æ»šå¯èƒ½éœ€è¦æ›´å¤æ‚çš„é€»è¾‘
#                     pass
            
#             s.commit()
        
#         return {
#             "status": "success",
#             "snapshot_id": snapshot_id,
#             "message": f"Rolled back to snapshot {snapshot_id}"
#         }
        
#     except Exception as e:
#         raise RuntimeError(f"Failed to rollback: {str(e)}")


def list_snapshots() -> list:
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å¿«ç…§"""
    snapshots = []
    if os.path.exists(SNAPSHOTS_DIR):
        for filename in os.listdir(SNAPSHOTS_DIR):
            if filename.endswith(".json"):
                snapshot_id = filename[:-5]  # ç§»é™¤ .json åç¼€
                try:
                    snapshot = load_snapshot(snapshot_id)
                    snapshots.append({
                        "snapshot_id": snapshot_id,
                        "timestamp": snapshot.get("timestamp"),
                        "tables": list(snapshot.get("tables", {}).keys())
                    })
                except Exception:
                    continue
    
    return sorted(snapshots, key=lambda x: x.get("timestamp", ""), reverse=True)

if __name__ == "__main__":
    print("ğŸš€ test snapshot ...")
    print("1 åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å¿«ç…§ ...")
    id = list_snapshots()
    print(id)
    print("""2 å›æ»šåˆ°æŒ‡å®šçš„å¿«ç…§
    æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªå±é™©æ“ä½œï¼Œéœ€è¦ç¡®è®¤
    
    Args:
        snapshot_id: å¿«ç…§ID
        confirm: æ˜¯å¦ç¡®è®¤æ‰§è¡Œå›æ»š
    
    Returns:
        å›æ»šç»“æœä¿¡æ¯.
          """)
    ans = input("\næŒ‡å®šçš„å¿«ç…§ID: ")
    if ans:
        result= rollback_to_snapshot(ans,True)